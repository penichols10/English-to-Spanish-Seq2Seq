{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spa.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = []\n",
    "spanish = []\n",
    "for line in text:\n",
    "    line = line.split('\\t')\n",
    "    english.append(line[0])\n",
    "    spanish.append(line[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(english, spanish, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Text\n",
    "def preprocess(line):\n",
    "    line = ''.join([char for char in line if char not in punctuation + '¿'])\n",
    "    return word_tokenize(line.lower())\n",
    "    \n",
    "eng_train, spa_train, eng_lens, spa_lens = [], [], [], []\n",
    "\n",
    "for eng_line, spa_line in zip(x_train, y_train):\n",
    "    spa_line = ['START'] + preprocess(spa_line) + ['END']\n",
    "    eng_line = preprocess(eng_line)\n",
    "    eng_train.append(eng_line)\n",
    "    spa_train.append(spa_line)\n",
    "    \n",
    "    # For finding longest spanish and english sequences\n",
    "    eng_lens.append(len(eng_line))\n",
    "    spa_lens.append(len(spa_line))\n",
    "    \n",
    "max_len_eng = max(eng_lens)\n",
    "max_len_spa = max(spa_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create token lookup dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tok_lookup(corpus):\n",
    "    flat_corpus = []\n",
    "    for line in corpus:\n",
    "        flat_corpus.extend(line)\n",
    "        \n",
    "    vocab = list(set(flat_corpus))\n",
    "    tok2idx = dict([(tok, idx) for idx, tok in enumerate(vocab, start=2)])\n",
    "    tok2idx['PAD'] = 0\n",
    "    tok2idx['OOV'] = 1\n",
    "    \n",
    "    return tok2idx\n",
    "\n",
    "tok2idx_eng = make_tok_lookup(eng_train)\n",
    "idx2tok_eng = dict([(key, word) for word, key in tok2idx_eng.items()])\n",
    "vocab_size_eng = len(tok2idx_eng)\n",
    "\n",
    "tok2idx_spa = make_tok_lookup(spa_train)\n",
    "idx2tok_spa = dict([(key, word) for word, key in tok2idx_spa.items()])\n",
    "vocab_size_spa = len(tok2idx_spa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Encoder Inputs, Decoder Inputs, Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = np.zeros((len(eng_train), max_len_eng))\n",
    "\n",
    "decoder_inputs = np.zeros((len(spa_train), max_len_spa))\n",
    "\n",
    "decoder_targets = np.zeros((len(spa_train), max_len_spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(eng_train):\n",
    "    for j, tok in enumerate(sequence):\n",
    "        encoder_inputs[i][j] = tok2idx_eng[tok]\n",
    "        \n",
    "for i, sequence in enumerate(spa_train):\n",
    "    for j, tok in enumerate(sequence):\n",
    "        decoder_inputs[i][j] = tok2idx_spa[tok]\n",
    "    # Targets sequences are decode inputs shifted by 1 (excluding START token)\n",
    "    # ex. if decode input is 'START my name is patrick', target is 'name is patrick'\n",
    "        if j > 0:\n",
    "            decoder_targets[i][j-1] = tok2idx_spa[tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125111, 70)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, None, 100)    1394700     ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 100)    2710800     ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 128),        117248      ['encoder_embedding[0][0]']      \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 128),  117248      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 128),                     'encoder_lstm[0][1]',           \n",
      "                                 (None, 128)]                     'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " decoder_classifier (Dense)     (None, None, 27108)  3496932     ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,836,928\n",
      "Trainable params: 7,836,928\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "embed_dim = 100\n",
    "\n",
    "# Encoder (encodes english sentence)\n",
    "enc_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "enc_embedding = Embedding(vocab_size_eng, embed_dim, name='encoder_embedding')\n",
    "x = enc_embedding(enc_inputs)\n",
    "enc_lstm = LSTM(hidden_size, return_state=True, name='encoder_lstm')\n",
    "_, enc_h, enc_c = enc_lstm(x)\n",
    "\n",
    "# Decoder (using LSTM initialized with encoder hidden states, predict next character in sequence)\n",
    "# Note, at training stage, the decoder sees the actual character in the sequence, too\n",
    "dec_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "dec_embedding = Embedding(vocab_size_spa, embed_dim, name='decoder_embedding')\n",
    "x = dec_embedding(dec_inputs)\n",
    "dec_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "# initialize decoder LSTM with states from the encoded sequence\n",
    "dec_outputs, _, _ = dec_lstm(x, initial_state=[enc_h, enc_c])\n",
    "# Predict the next token\n",
    "dec_classifier = Dense(vocab_size_spa, activation='softmax', name='decoder_classifier')\n",
    "outputs =  dec_classifier(dec_outputs)\n",
    "\n",
    "\n",
    "model = Model([enc_inputs, dec_inputs], outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3519/3519 [==============================] - 1468s 416ms/step - loss: 0.6310 - accuracy: 0.9183 - val_loss: 0.4932 - val_accuracy: 0.9240\n",
      "Epoch 2/50\n",
      "3519/3519 [==============================] - 1363s 388ms/step - loss: 0.4486 - accuracy: 0.9283 - val_loss: 0.4250 - val_accuracy: 0.9313\n",
      "Epoch 3/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.3885 - accuracy: 0.9342 - val_loss: 0.3901 - val_accuracy: 0.9356\n",
      "Epoch 4/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.3479 - accuracy: 0.9387 - val_loss: 0.3640 - val_accuracy: 0.9389\n",
      "Epoch 5/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.3135 - accuracy: 0.9427 - val_loss: 0.3441 - val_accuracy: 0.9418\n",
      "Epoch 6/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.2848 - accuracy: 0.9461 - val_loss: 0.3293 - val_accuracy: 0.9441\n",
      "Epoch 7/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.2597 - accuracy: 0.9492 - val_loss: 0.3171 - val_accuracy: 0.9460\n",
      "Epoch 8/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.2375 - accuracy: 0.9521 - val_loss: 0.3076 - val_accuracy: 0.9476\n",
      "Epoch 9/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.2179 - accuracy: 0.9548 - val_loss: 0.3005 - val_accuracy: 0.9489\n",
      "Epoch 10/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.2005 - accuracy: 0.9574 - val_loss: 0.2945 - val_accuracy: 0.9500\n",
      "Epoch 11/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1850 - accuracy: 0.9599 - val_loss: 0.2903 - val_accuracy: 0.9509\n",
      "Epoch 12/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1710 - accuracy: 0.9623 - val_loss: 0.2870 - val_accuracy: 0.9518\n",
      "Epoch 13/50\n",
      "3519/3519 [==============================] - 681s 194ms/step - loss: 0.1588 - accuracy: 0.9644 - val_loss: 0.2849 - val_accuracy: 0.9525\n",
      "Epoch 14/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1480 - accuracy: 0.9664 - val_loss: 0.2834 - val_accuracy: 0.9530\n",
      "Epoch 15/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1384 - accuracy: 0.9682 - val_loss: 0.2826 - val_accuracy: 0.9533\n",
      "Epoch 16/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1299 - accuracy: 0.9699 - val_loss: 0.2834 - val_accuracy: 0.9535\n",
      "Epoch 17/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1223 - accuracy: 0.9714 - val_loss: 0.2844 - val_accuracy: 0.9538\n",
      "Epoch 18/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1156 - accuracy: 0.9728 - val_loss: 0.2860 - val_accuracy: 0.9538\n",
      "Epoch 19/50\n",
      "3519/3519 [==============================] - 134s 38ms/step - loss: 0.1095 - accuracy: 0.9741 - val_loss: 0.2873 - val_accuracy: 0.9540\n",
      "Epoch 20/50\n",
      "1817/3519 [==============>...............] - ETA: 1:18 - loss: 0.1008 - accuracy: 0.9761"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28512/3102810704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Patrick\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    restore_best_weights=False\n",
    ")\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    filepath='eng_to_spa.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit([encoder_inputs, decoder_inputs], decoder_targets, validation_split=0.1, epochs=50, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************ENCODER MODEL********************************************\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_inputs (InputLayer)  [(None, None)]           0         \n",
      "                                                                 \n",
      " encoder_embedding (Embeddin  (None, None, 100)        1394700   \n",
      " g)                                                              \n",
      "                                                                 \n",
      " encoder_lstm (LSTM)         [(None, 128),             117248    \n",
      "                              (None, 128),                       \n",
      "                              (None, 128)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,511,948\n",
      "Trainable params: 1,511,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None \n",
      "\n",
      "\n",
      "*******************************************DECODER MODEL********************************************\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 100)    2710800     ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " inf_dec_h_input (InputLayer)   [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " inf_dec_c_input (InputLayer)   [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, None, 128),  117248      ['decoder_embedding[1][0]',      \n",
      "                                 (None, 128),                     'inf_dec_h_input[0][0]',        \n",
      "                                 (None, 128)]                     'inf_dec_c_input[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_classifier (Dense)     (None, None, 27108)  3496932     ['decoder_lstm[1][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,324,980\n",
      "Trainable params: 6,324,980\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Inference encoder (input sequence --> LSTM states)\n",
    "encoder = Model(enc_inputs, [enc_h, enc_c])\n",
    "\n",
    "# Decoder inference (encoder LSTM states --> predictions)\n",
    "dec_input_h = Input(shape=(hidden_size,), name='inf_dec_h_input')\n",
    "dec_input_c = Input(shape=(hidden_size,), name='inf_dec_c_input')\n",
    "\n",
    "x = dec_embedding(dec_inputs)\n",
    "dec_outputs, dec_h, dec_c = dec_lstm(x, initial_state=[dec_input_h, dec_input_c])\n",
    "outputs = dec_classifier(dec_outputs)\n",
    "\n",
    "decoder = Model([dec_inputs] + [dec_input_h, dec_input_c],\n",
    "                [outputs] + [dec_h, dec_c])\n",
    "\n",
    "print('ENCODER MODEL'.center(100, '*'))\n",
    "print(encoder.summary(), '\\n\\n')\n",
    "\n",
    "print('DECODER MODEL'.center(100, '*'))\n",
    "print(decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'test', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
     ]
    }
   ],
   "source": [
    "def eng_to_vec(sentence):\n",
    "    '''\n",
    "    Vectorizes an english sentence\n",
    "    '''\n",
    "    no_punct = ''.join([char for char in sentence if char not in punctuation])\n",
    "    no_punct = no_punct.lower()\n",
    "    tokenized = word_tokenize(no_punct)\n",
    "    vector = np.zeros((1, max_len_eng))\n",
    "    \n",
    "    for i, word in enumerate(tokenized):\n",
    "        idx = tok2idx_eng.get(word)\n",
    "        # Map OOV words to OOV index\n",
    "        if word is None:\n",
    "            idx = 1\n",
    "        vector[0][i] = idx\n",
    "        \n",
    "    return vector\n",
    "    \n",
    "print([idx2tok_eng[idx] for idx in eng_to_vec('this is a test')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: It's up to you to make a choice.\n",
      "Predicted Spanish: es necesario que te pongas loco\n",
      "True Spanish: Depende de ti tomar una decisión. \n",
      "\n",
      "English: Since he says so, it must be true.\n",
      "Predicted Spanish: eso lo hace decir que te diga\n",
      "True Spanish: Ya que él lo dice, debe ser verdad. \n",
      "\n",
      "English: The peace talks failed once again.\n",
      "Predicted Spanish: las cosas hacen nada que lo que perder\n",
      "True Spanish: Los diálogos de paz fracasaron otra vez. \n",
      "\n",
      "English: Tom is doing very well.\n",
      "Predicted Spanish: tom está muy bien\n",
      "True Spanish: A Tom le va muy bien. \n",
      "\n",
      "English: I'm ready to vote.\n",
      "Predicted Spanish: estoy listo para votar\n",
      "True Spanish: Estoy preparado para votar. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def vec_to_spa(vector):\n",
    "    '''\n",
    "    Converts a vector into a spanish string\n",
    "    Params, vector shape: (sequence length)\n",
    "    '''\n",
    "    output = ' '.join([idx2tok_spa[int(idx)] for idx in vector])\n",
    "    return output\n",
    "\n",
    "def translate(sentence):\n",
    "    # Vectorize and encode sentence, calculate initial hidden state\n",
    "    vector = eng_to_vec(sentence)\n",
    "    encoder_states = encoder.predict(vector, verbose=0)\n",
    "    h, c = encoder_states[0], encoder_states[1]    \n",
    "    \n",
    "    # Initialize output sequence\n",
    "    output_sequence = np.asarray([tok2idx_spa['START']])\n",
    "    output_sequence = np.expand_dims(output_sequence, axis=0)\n",
    "    seq_len = 0\n",
    "    output_vector = []\n",
    "    end = False\n",
    "    \n",
    "    while not end:\n",
    "        # Predict next token \n",
    "        outputs, h, c = decoder.predict([output_sequence, h, c], verbose=0) # (output is (1, sequence length, vocab_size_spa))\n",
    "        \n",
    "        # Get next token using argmax (naive solution, constraint on performance)\n",
    "        next_tok_idx = np.argmax(outputs[0, -1, :]) # second index here means we want highestt probability of next word in sequence\n",
    "\n",
    "        # Update output seqwuence\n",
    "        output_sequence = np.zeros((1, 1))\n",
    "        output_sequence[0][0] = next_tok_idx\n",
    "        \n",
    "        # Check if sequence is over\n",
    "        seq_len += 1\n",
    "        if seq_len == max_len_spa or next_tok_idx == tok2idx_spa['END']:\n",
    "            end = True\n",
    "        else:\n",
    "            output_vector.append(next_tok_idx)\n",
    "    output_string = vec_to_spa(output_vector)\n",
    "    return output_string\n",
    "tests = ['hello', 'hi', 'i am going to the store', 'how are you']\n",
    "\n",
    "for i,test in enumerate(x_test[:5]):\n",
    "    print('English:', test)\n",
    "    print('Predicted Spanish:', translate(test))\n",
    "    print('True Spanish:', y_test[i], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0480a40de60fe0b4be044949303dbe98ce3610184aeb132e77bccbcbbb8df2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
